{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-08T10:18:38.573205Z",
     "iopub.status.busy": "2025-04-08T10:18:38.572854Z",
     "iopub.status.idle": "2025-04-08T10:18:42.547038Z",
     "shell.execute_reply": "2025-04-08T10:18:42.546128Z",
     "shell.execute_reply.started": "2025-04-08T10:18:38.573169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers evaluate seqeval datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T10:18:42.548954Z",
     "iopub.status.busy": "2025-04-08T10:18:42.548589Z",
     "iopub.status.idle": "2025-04-08T10:18:42.554906Z",
     "shell.execute_reply": "2025-04-08T10:18:42.554042Z",
     "shell.execute_reply.started": "2025-04-08T10:18:42.548917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments \n",
    "from torch.utils.data import Dataset\n",
    "import evaluate\n",
    "from collections import Counter\n",
    "from random import sample, choice\n",
    "from transformers import RobertaForTokenClassification, RobertaConfig\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "from transformers import EarlyStoppingCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T10:18:43.992685Z",
     "iopub.status.busy": "2025-04-08T10:18:43.992378Z",
     "iopub.status.idle": "2025-04-08T10:18:43.999912Z",
     "shell.execute_reply": "2025-04-08T10:18:43.999048Z",
     "shell.execute_reply.started": "2025-04-08T10:18:43.992662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_bio_file(file_path):\n",
    "    sentences = []\n",
    "    current_sentence = {'tokens': [], 'ner_labels': []}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    # Tách các từ ghép bằng dấu _\n",
    "                    token = parts[0].replace('_', ' ')\n",
    "                    pos, chunk, ner = parts[1], parts[2], parts[3]\n",
    "                    current_sentence['tokens'].append(token)\n",
    "                    current_sentence['ner_labels'].append(ner)\n",
    "            else:\n",
    "                if current_sentence['tokens']:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = {'tokens': [], 'ner_labels': []}\n",
    "    if current_sentence['tokens']:\n",
    "        sentences.append(current_sentence)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T10:19:49.954090Z",
     "iopub.status.busy": "2025-04-08T10:19:49.953808Z",
     "iopub.status.idle": "2025-04-08T10:19:54.804114Z",
     "shell.execute_reply": "2025-04-08T10:19:54.803305Z",
     "shell.execute_reply.started": "2025-04-08T10:19:49.954070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "train_data = read_bio_file('/kaggle/input/dataset-dev-test-train/train_data.txt')\n",
    "dev_data = read_bio_file('/kaggle/input/dataset-dev-test-train/dev_data.txt')\n",
    "test_data = read_bio_file('/kaggle/input/dataset-dev-test-train/test_data.txt')\n",
    "# Sau khi gọi read_bio_file\n",
    "# print(\"Train data sample (first 2 sentences, after normalization):\", train_data[:2])\n",
    "# print(\"Train data sample (first 2 sentences):\", train_data[:2])\n",
    "\n",
    "# print(\"Unique labels in train data:\", unique_labels)\n",
    "# print(\"Label2id mapping:\", label2id)\n",
    "# # In 2 mẫu cuối để kiểm tra\n",
    "# print_last_two_samples(train_data, \"train_data\")\n",
    "# print_last_two_samples(dev_data, \"dev_data\")\n",
    "# print_last_two_samples(test_data, \"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:02:21.658074Z",
     "iopub.status.busy": "2025-04-08T11:02:21.657765Z",
     "iopub.status.idle": "2025-04-08T11:02:22.205881Z",
     "shell.execute_reply": "2025-04-08T11:02:22.205064Z",
     "shell.execute_reply.started": "2025-04-08T11:02:21.658050Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is fast tokenizer: False\n",
      "Mapping NER labels to IDs: {'I-ĐT': 0, 'B-NG': 1, 'B-VBPL': 2, 'I-VBPL': 3, 'O': 4, 'I-NG': 5, 'B-SL': 6, 'B-CQ': 7, 'I-SL': 8, 'I-CQ': 9, 'B-ĐT': 10}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "print(\"Is fast tokenizer:\", tokenizer.is_fast)\n",
    "unique_labels = set(label for sentence in train_data for label in sentence['ner_labels'])\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(\"Mapping NER labels to IDs:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:02:47.400843Z",
     "iopub.status.busy": "2025-04-08T11:02:47.400475Z",
     "iopub.status.idle": "2025-04-08T11:02:47.406958Z",
     "shell.execute_reply": "2025-04-08T11:02:47.406068Z",
     "shell.execute_reply.started": "2025-04-08T11:02:47.400813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'O': 0, 'B-SL': 1, 'I-SL': 2, 'B-CQ': 3, 'I-CQ': 4, 'B-ĐT': 5, 'I-ĐT': 6, 'B-VBPL': 7, 'I-VBPL': 8, 'B-NG': 9, 'I-NG': 10}\n",
      "id2label: {0: 'O', 1: 'B-SL', 2: 'I-SL', 3: 'B-CQ', 4: 'I-CQ', 5: 'B-ĐT', 6: 'I-ĐT', 7: 'B-VBPL', 8: 'I-VBPL', 9: 'B-NG', 10: 'I-NG'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = ['O', 'B-SL', 'I-SL', 'B-CQ', 'I-CQ', 'B-ĐT', 'I-ĐT', 'B-VBPL', 'I-VBPL', 'B-NG', 'I-NG']\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:25:09.264368Z",
     "iopub.status.busy": "2025-04-08T11:25:09.264025Z",
     "iopub.status.idle": "2025-04-08T11:25:09.275114Z",
     "shell.execute_reply": "2025-04-08T11:25:09.274203Z",
     "shell.execute_reply.started": "2025-04-08T11:25:09.264344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_to_features(sentences, max_len=128):\n",
    "    input_ids, attention_masks, label_ids = [], [], []\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence['tokens']  # Dữ liệu đã được chuẩn hóa\n",
    "        labels = sentence['ner_labels']\n",
    "        if not tokens or not labels:\n",
    "            print(f\"Warning: Empty sentence found - Tokens: {tokens}, Labels: {labels}\")\n",
    "            continue\n",
    "        \n",
    "        # Chuẩn hóa tokens: thêm khoảng trắng giữa các từ\n",
    "        tokenized_input = \" \".join(tokens)\n",
    "        \n",
    "        # Mã hóa tokens bằng PhoBERT\n",
    "        encoding = tokenizer(tokenized_input, return_tensors='pt', max_length=max_len, padding='max_length', truncation=True)\n",
    "        attention_mask = encoding['attention_mask'][0]\n",
    "        input_ids_batch = encoding['input_ids'][0]\n",
    "        \n",
    "        # Tạo label_encoding với -100\n",
    "        label_encoding = [-100] * max_len\n",
    "        \n",
    "        # Lấy input_tokens\n",
    "        input_tokens = tokenizer.convert_ids_to_tokens(input_ids_batch)\n",
    "        \n",
    "        # Tính word_ids bằng cách so sánh input_tokens với tokens\n",
    "        word_ids = []\n",
    "        token_idx = 0\n",
    "        for i, token in enumerate(input_tokens):\n",
    "            if token in ['<s>', '</s>', '[PAD]']:\n",
    "                word_ids.append(None)\n",
    "                continue\n",
    "            if token_idx >= len(tokens):  # Dừng lại nếu đã ánh xạ hết tokens\n",
    "                word_ids.append(None)\n",
    "                continue\n",
    "            # Loại bỏ ký tự đặc biệt (nếu có) và so sánh với token gốc\n",
    "            token_clean = token.replace('@@', '')\n",
    "            # Tìm token gốc tương ứng\n",
    "            found = False\n",
    "            for j in range(token_idx, len(tokens)):\n",
    "                if token_clean.lower() in tokens[j].lower():\n",
    "                    word_ids.append(j)\n",
    "                    token_idx = j + 1\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                word_ids.append(None)\n",
    "        \n",
    "        # Ánh xạ nhãn\n",
    "        for j, word_id in enumerate(word_ids):\n",
    "            if word_id is not None and word_id < len(labels):\n",
    "                if labels[word_id] not in label2id:\n",
    "                    print(f\"Warning: Unknown label '{labels[word_id]}' at sentence: {tokens}\")\n",
    "                    label_encoding[j] = -100\n",
    "                else:\n",
    "                    label_encoding[j] = label2id[labels[word_id]]\n",
    "        \n",
    "        input_ids.append(input_ids_batch)\n",
    "        attention_masks.append(attention_mask)\n",
    "        label_ids.append(torch.tensor(label_encoding))\n",
    "    \n",
    "    if not input_ids:\n",
    "        raise ValueError(\"No valid data to convert!\")\n",
    "    \n",
    "    # In thông tin để kiểm tra\n",
    "    print(\"Sample tokens (first sentence):\", sentences[0]['tokens'])\n",
    "    print(\"Sample labels (first sentence):\", sentences[0]['ner_labels'])\n",
    "    print(\"Sample input_tokens (first sentence):\", input_tokens)\n",
    "    print(\"Sample word_ids (first sentence):\", word_ids)\n",
    "    print(\"Sample label_ids (first sentence):\", label_ids[0].tolist())\n",
    "    return torch.stack(input_ids), torch.stack(attention_masks), torch.stack(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:25:10.675780Z",
     "iopub.status.busy": "2025-04-08T11:25:10.675468Z",
     "iopub.status.idle": "2025-04-08T11:27:44.865070Z",
     "shell.execute_reply": "2025-04-08T11:27:44.864050Z",
     "shell.execute_reply.started": "2025-04-08T11:25:10.675754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens (first sentence): ['0', 'đồng', 'c', 'Phạm tội', 'thuộc', 'trường hợp', 'quy định', 'tại', 'khoản', '3', 'Điều', 'này', ',', 'thì', 'bị', 'phạt', 'tiền', 'từ', '1', '.']\n",
      "Sample labels (first sentence): ['B-SL', 'I-SL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Sample input_tokens (first sentence): ['<s>', 'Cấp', 'điều', 'chỉnh', ',', 'bổ', 'sung', 'nội', 'dung', 'chứng', 'chỉ', 'năng', 'lực', 'hoạt', 'động', 'xây', 'dựng', 'hạng', 'II', ',', 'hạng', 'III', 'do', 'cấp', 'Cấp', 'Tỉnh', 'thực', 'hiện', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Sample word_ids (first sentence): [None, 0, 1, None, 2, 3, None, 4, None, 5, None, 6, None, 7, None, 8, None, 9, 10, 11, 12, 13, 14, 15, 16, None, 17, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Sample label_ids (first sentence): [-100, 6, 8, 4, 4, -100, 4, 4, -100, 4, -100, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "Sample tokens (first sentence): ['Đăng ký', 'thành lập', 'doanh nghiệp', 'tư nhân', 'do', 'cơ quan', 'phòng đăng ký kinh doanh', 'sở kế hoạch và đầu tư tỉnh thái bình', 'thực hiện']\n",
      "Sample labels (first sentence): ['O', 'O', 'B-ĐT', 'I-ĐT', 'O', 'O', 'B-CQ', 'B-CQ', 'O']\n",
      "Sample input_tokens (first sentence): ['<s>', 'Chuyển', 'nhượng', 'quyền', 'khai', 'thác', 'khoáng', 'sản', 'cấp', 'tỉnh', 'có', 'phí', ',', 'lệ', 'phí', 'là', 'Trực', 'tiếp', '500.000', 'đồng', '5.000.000', 'đồng', '7.@@', '500.000', 'đồng', '7.@@', '500.000', 'đồng', '10.000.000', 'đồng', '15@@', '.000.000', 'đồng', '20.000.000', 'đồng', '20.000.000', 'đồng', '25@@', '.000.000', 'đồng', '30.000.000', 'đồng', '40@@', '.000.000', 'đồng', '50.000.000', 'đồng', 'Trực', 'tuyến', '500.000', 'đồng', '5.000.000', 'đồng', '7.@@', '500.000', 'đồng', '7.@@', '500.000', 'đồng', '10.000.000', 'đồng', '15@@', '.000.000', 'đồng', '20.000.000', 'đồng', '20.000.000', 'đồng', '25@@', '.000.000', 'đồng', '30.000.000', 'đồng', '40@@', '.000.000', 'đồng', '50.000.000', 'đồng', 'Dịch', 'vụ', 'b@@', 'ưu', 'chính', '10.000.000', 'đồng', '15@@', '.000.000', 'đồng', '20.000.000', 'đồng', '20.000.000', 'đồng', '25@@', '.000.000', 'đồng', '30.000.000', 'đồng', '40@@', '.000@@', '.000@@', 'đồng', '50.000.000', 'đồng', '500.000', 'đồng', '5.000.000', 'đồng', '7.@@', '500.000', 'đồng', '7.@@', '500.000', 'đồng', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Sample word_ids (first sentence): [None, 0, None, 1, 2, None, 3, None, 4, 5, 6, 7, 8, 9, None, 10, 11, None, 12, 13, 14, 15, 16, 18, 19, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 67, 68, 71, 73, 74, None, 75, None, 76, 77, None, 79, None, None, 82, 83, None, 85, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Sample label_ids (first sentence): [-100, 4, 7, -100, -100, -100, -100, 7, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "Sample tokens (first sentence): ['Cấp', 'lại', 'Giấy', 'chứng nhận', 'huấn luyện', 'kỹ thuật', 'an toàn', 'vật liệu', 'nổ', 'công nghiệp', 'thuộc', 'thẩm quyền', 'giải quyết', 'của', 'sở công thương', 'thực hiện', 'Trực tiếp', '3', 'Ngày', 'Dịch vụ', 'bưu chính', '3', 'Ngày']\n",
      "Sample labels (first sentence): ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CQ', 'O', 'O', 'B-NG', 'I-NG', 'O', 'O', 'B-NG', 'I-NG']\n",
      "Sample input_tokens (first sentence): ['<s>', 'Đăng', 'ký', 'lại', 'phương', 'tiện', 'trong', 'trường', 'hợp', 'phương', 'tiện', 'thay', 'đổi', 'tên', ',', 'tính', 'năng', 'kỹ', 'thuật', 'do', 'cơ', 'quan', 'cục', 'đường', 'thuỷ', 'nội', 'địa', 'việt', 'nam', 'sở', 'giao', 'thông', 'vận', 'tải', 'chi', 'cục', 'đường', 'thuỷ', 'nội', 'địa', 'uỷ', 'ban', 'nhân', 'dân', 'cấp', 'xã', 'uỷ', 'ban', 'nhân', 'dân', 'cấp', 'huyện', 'thực', 'hiện', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Sample word_ids (first sentence): [None, 0, None, 1, 2, 5, None, None, None, None, None, 6, None, 7, 8, 9, None, 10, None, 11, 12, None, 13, 15, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 16, 17, None, None, None, None, None, None, None, None, None, None, 18, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Sample label_ids (first sentence): [-100, 4, 4, 4, 4, -100, 4, -100, 4, -100, 4, -100, 4, -100, 4, 4, -100, 4, 4, -100, 4, -100, 4, 7, -100, -100, 4, -100, 4, -100, 1, 5, 4, -100, 4, -100, -100, 1, 5, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_masks, train_labels = convert_to_features(train_data, max_len=128)\n",
    "dev_inputs, dev_masks, dev_labels = convert_to_features(dev_data, max_len=128)\n",
    "test_inputs, test_masks, test_labels = convert_to_features(test_data, max_len=128)\n",
    "\n",
    "# print(\"Train inputs shape:\", train_inputs.shape)\n",
    "# print(\"Train labels shape:\", train_labels.shape)\n",
    "# print(\"Sample train_labels (first 3 sentences):\")\n",
    "# for i in range(min(3, len(train_labels))):\n",
    "# print(f\"Sentence {i}: {train_labels[i].tolist()}\")\n",
    "# print(\"Dev inputs shape:\", dev_inputs.shape)\n",
    "# print(\"Dev labels shape:\", dev_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:44:45.669803Z",
     "iopub.status.busy": "2025-04-08T04:44:45.669469Z",
     "iopub.status.idle": "2025-04-08T04:44:45.675122Z",
     "shell.execute_reply": "2025-04-08T04:44:45.674079Z",
     "shell.execute_reply.started": "2025-04-08T04:44:45.669768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.label_ids = label_ids\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_masks[idx], 'labels': self.label_ids[idx]}\n",
    "\n",
    "# Tạo dataset\n",
    "train_dataset = NERDataset(train_inputs, train_masks, train_labels)\n",
    "dev_dataset = NERDataset(dev_inputs, dev_masks, dev_labels)\n",
    "test_dataset = NERDataset(test_inputs, test_masks, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:06:07.831277Z",
     "iopub.status.busy": "2025-04-08T11:06:07.830918Z",
     "iopub.status.idle": "2025-04-08T11:06:08.021033Z",
     "shell.execute_reply": "2025-04-08T11:06:08.020018Z",
     "shell.execute_reply.started": "2025-04-08T11:06:07.831251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping NER labels to IDs: {'I-ĐT': 0, 'B-NG': 1, 'B-VBPL': 2, 'I-VBPL': 3, 'O': 4, 'I-NG': 5, 'B-SL': 6, 'B-CQ': 7, 'I-SL': 8, 'I-CQ': 9, 'B-ĐT': 10}\n",
      "id2label: {0: 'I-ĐT', 1: 'B-NG', 2: 'B-VBPL', 3: 'I-VBPL', 4: 'O', 5: 'I-NG', 6: 'B-SL', 7: 'B-CQ', 8: 'I-SL', 9: 'I-CQ', 10: 'B-ĐT'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set(label for sentence in train_data for label in sentence['ner_labels'])\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "print(\"Mapping NER labels to IDs:\", label2id)\n",
    "print(\"id2label:\", id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:44:53.793007Z",
     "iopub.status.busy": "2025-04-08T04:44:53.792694Z",
     "iopub.status.idle": "2025-04-08T04:44:54.177381Z",
     "shell.execute_reply": "2025-04-08T04:44:54.175561Z",
     "shell.execute_reply.started": "2025-04-08T04:44:53.792984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phân bố nhãn trong dữ liệu huấn luyện:\n",
      "B-SL: 11060 (0.34%)\n",
      "I-SL: 12798 (0.40%)\n",
      "O: 2890348 (89.70%)\n",
      "B-CQ: 48418 (1.50%)\n",
      "B-ĐT: 52500 (1.63%)\n",
      "B-VBPL: 23827 (0.74%)\n",
      "I-VBPL: 78787 (2.45%)\n",
      "B-NG: 27642 (0.86%)\n",
      "I-NG: 27639 (0.86%)\n",
      "I-CQ: 12915 (0.40%)\n",
      "I-ĐT: 36200 (1.12%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_labels = [label for sentence in train_data for label in sentence['ner_labels']]\n",
    "label_counts = Counter(all_labels)\n",
    "total_labels = sum(label_counts.values())\n",
    "print(\"Phân bố nhãn trong dữ liệu huấn luyện:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count} ({count/total_labels*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:45:03.407499Z",
     "iopub.status.busy": "2025-04-08T04:45:03.407138Z",
     "iopub.status.idle": "2025-04-08T04:45:03.413216Z",
     "shell.execute_reply": "2025-04-08T04:45:03.412490Z",
     "shell.execute_reply.started": "2025-04-08T04:45:03.407472Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated before training: 0.0 GiB\n",
      "Memory reserved before training: 0.0 GiB\n"
     ]
    }
   ],
   "source": [
    "# Thiết lập để giảm fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Giải phóng bộ nhớ GPU\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Memory allocated before training:\", torch.cuda.memory_allocated() / 1024**3, \"GiB\")\n",
    "print(\"Memory reserved before training:\", torch.cuda.memory_reserved() / 1024**3, \"GiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:45:08.408093Z",
     "iopub.status.busy": "2025-04-08T04:45:08.407759Z",
     "iopub.status.idle": "2025-04-08T04:49:51.753087Z",
     "shell.execute_reply": "2025-04-08T04:49:51.752035Z",
     "shell.execute_reply.started": "2025-04-08T04:45:08.408067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample label_ids (first sentence): [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# Oversampling và undersampling\n",
    "only_o_sentences = [s for s in train_data if all(label == 'O' for label in s['ner_labels'])]\n",
    "entity_sentences = [s for s in train_data if any(label != 'O' for label in s['ner_labels'])]\n",
    "dt_sentences = [s for s in entity_sentences if any(label in ['I-ĐT', 'B-ĐT'] for label in s['ner_labels'])]\n",
    "reduced_o_sentences = sample(only_o_sentences, int(0.1 * len(only_o_sentences)))\n",
    "oversampled_entity_sentences = [choice(entity_sentences) for _ in range(2 * len(entity_sentences))]\n",
    "oversampled_dt_sentences = [choice(dt_sentences) for _ in range(2 * len(dt_sentences))]\n",
    "balanced_train_data = reduced_o_sentences + oversampled_entity_sentences + oversampled_dt_sentences\n",
    "\n",
    "# Cập nhật dataset\n",
    "train_inputs, train_masks, train_labels = convert_to_features(balanced_train_data)\n",
    "train_dataset = NERDataset(train_inputs, train_masks, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:49:51.754856Z",
     "iopub.status.busy": "2025-04-08T04:49:51.754477Z",
     "iopub.status.idle": "2025-04-08T04:49:51.761839Z",
     "shell.execute_reply": "2025-04-08T04:49:51.760668Z",
     "shell.execute_reply.started": "2025-04-08T04:49:51.754820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomPhoBERTForTokenClassification(RobertaForTokenClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        label_counts = Counter([label for sentence in balanced_train_data for label in sentence['ner_labels']])\n",
    "        total = sum(label_counts.values())\n",
    "        class_weights = torch.tensor([total / (len(label2id) * label_counts.get(label, 1)) * (20 if label in ['I-ĐT', 'B-ĐT'] else 10 if label != 'O' else 1) for label in label2id], dtype=torch.float)\n",
    "        self.register_buffer('class_weights', class_weights)\n",
    "        print(\"Class weights:\", self.class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:49:51.763964Z",
     "iopub.status.busy": "2025-04-08T04:49:51.763659Z",
     "iopub.status.idle": "2025-04-08T04:49:51.782011Z",
     "shell.execute_reply": "2025-04-08T04:49:51.780892Z",
     "shell.execute_reply.started": "2025-04-08T04:49:51.763942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        return (loss, logits) if loss is not None else logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:49:51.783607Z",
     "iopub.status.busy": "2025-04-08T04:49:51.783278Z",
     "iopub.status.idle": "2025-04-08T04:49:56.408909Z",
     "shell.execute_reply": "2025-04-08T04:49:56.407689Z",
     "shell.execute_reply.started": "2025-04-08T04:49:51.783576Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67daf8bb5884b3cbd6df7ff79cacce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([7.4158e+01, 7.4889e+01, 8.5020e+01, 2.6256e+01, 1.0908e-01, 7.4904e+01,\n",
      "        1.9303e+02, 4.3297e+01, 1.6164e+02, 1.6773e+02, 5.0882e+01])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomPhoBERTForTokenClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['class_weights', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomPhoBERTForTokenClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "config.num_labels = len(label2id)\n",
    "config.hidden_dropout_prob = 0.2  # Tùy chọn: điều chỉnh dropout mặc định\n",
    "config.attention_probs_dropout_prob = 0.2  # Tùy chọn: điều chỉnh dropout mặc định\n",
    "\n",
    "model = CustomPhoBERTForTokenClassification.from_pretrained(\n",
    "    \"vinai/phobert-base-v2\",\n",
    "    config=config\n",
    ")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:49:56.410725Z",
     "iopub.status.busy": "2025-04-08T04:49:56.410343Z",
     "iopub.status.idle": "2025-04-08T04:49:56.870812Z",
     "shell.execute_reply": "2025-04-08T04:49:56.869747Z",
     "shell.execute_reply.started": "2025-04-08T04:49:56.410694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0733944ab72e4f8e81824b7b947c2b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metric đánh giá\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    pred_labels = [[id2label[p] for p, l in zip(pred, label) if l != -100] for pred, label in zip(predictions, labels)]\n",
    "    results = metric.compute(predictions=pred_labels, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Thiết lập huấn luyện\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    # eval_steps=5000,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=1000,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.1,\n",
    "    logging_dir='./logs',\n",
    "    save_strategy=\"epoch\",\n",
    "    # save_setps=5000,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\",\n",
    "    logging_steps=500,  # In loss mỗi 500 bước\n",
    "    max_grad_norm=1.0,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    dataloader_pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T04:49:56.872784Z",
     "iopub.status.busy": "2025-04-08T04:49:56.872368Z",
     "iopub.status.idle": "2025-04-08T06:58:13.755612Z",
     "shell.execute_reply": "2025-04-08T06:58:13.754768Z",
     "shell.execute_reply.started": "2025-04-08T04:49:56.872741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5670' max='5670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5670/5670 2:07:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.070374</td>\n",
       "      <td>0.833004</td>\n",
       "      <td>0.878643</td>\n",
       "      <td>0.855215</td>\n",
       "      <td>0.986096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.820818</td>\n",
       "      <td>0.868078</td>\n",
       "      <td>0.843787</td>\n",
       "      <td>0.986641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.068509</td>\n",
       "      <td>0.831307</td>\n",
       "      <td>0.878093</td>\n",
       "      <td>0.854060</td>\n",
       "      <td>0.988354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.07566389441490173, 'eval_precision': 0.7816128020081582, 'eval_recall': 0.8527901403628895, 'eval_f1': 0.8156516044531763, 'eval_accuracy': 0.9845376654018292, 'eval_runtime': 55.9405, 'eval_samples_per_second': 183.731, 'eval_steps_per_second': 1.448, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Huấn luyện và đánh giá\n",
    "trainer.train()\n",
    "trainer.save_model(\"/kaggle/working/results/final_model\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/results/final_model\")\n",
    "torch.save(training_args, \"/kaggle/working/results/final_model/training_args.bin\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T07:14:46.549201Z",
     "iopub.status.busy": "2025-04-08T07:14:46.548870Z",
     "iopub.status.idle": "2025-04-08T07:16:56.686862Z",
     "shell.execute_reply": "2025-04-08T07:16:56.686081Z",
     "shell.execute_reply.started": "2025-04-08T07:14:46.549176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CQ       0.89      0.92      0.91     19516\n",
      "          NG       0.97      1.00      0.99       481\n",
      "          SL       0.97      1.00      0.98       496\n",
      "        VBPL       1.00      1.00      1.00        44\n",
      "          ĐT       0.60      0.69      0.64      4925\n",
      "\n",
      "   micro avg       0.83      0.88      0.86     25462\n",
      "   macro avg       0.89      0.92      0.90     25462\n",
      "weighted avg       0.84      0.88      0.86     25462\n",
      "\n",
      "True label counts: Counter({'O': 1148544, 'I-SL': 63488, 'I-NG': 61568, 'B-CQ': 19456, 'I-ĐT': 7808, 'I-CQ': 7680, 'I-VBPL': 5632, 'B-ĐT': 4864})\n",
      "Predicted label counts: Counter({'O': 1141100, 'I-SL': 63578, 'I-NG': 63232, 'B-CQ': 20095, 'I-ĐT': 11527, 'I-CQ': 8372, 'I-VBPL': 5632, 'B-ĐT': 5504})\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions, labels, _ = trainer.predict(dev_dataset)\n",
    "pred_labels = np.argmax(predictions, axis=-1)\n",
    "true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "pred_labels = [[id2label[p] for p, l in zip(pred, label) if l != -100] for pred, label in zip(pred_labels, labels)]\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "from collections import Counter\n",
    "true_counts = Counter([l for sublist in true_labels for l in sublist])\n",
    "pred_counts = Counter([l for sublist in pred_labels for l in sublist])\n",
    "print(\"True label counts:\", true_counts)\n",
    "print(\"Predicted label counts:\", pred_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T07:28:03.218503Z",
     "iopub.status.busy": "2025-04-08T07:28:03.218134Z",
     "iopub.status.idle": "2025-04-08T07:28:14.726735Z",
     "shell.execute_reply": "2025-04-08T07:28:14.725886Z",
     "shell.execute_reply.started": "2025-04-08T07:28:03.218479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample label_ids (first sentence): [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu test\n",
    "test_data = read_bio_file('/kaggle/input/dataset-dev-test-train/test_data.txt')\n",
    "\n",
    "# Tiền xử lý dữ liệu test\n",
    "test_inputs, test_masks, test_labels = convert_to_features(test_data)\n",
    "test_dataset = NERDataset(test_inputs, test_masks, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T07:28:17.447114Z",
     "iopub.status.busy": "2025-04-08T07:28:17.446787Z",
     "iopub.status.idle": "2025-04-08T07:28:18.513218Z",
     "shell.execute_reply": "2025-04-08T07:28:18.512442Z",
     "shell.execute_reply.started": "2025-04-08T07:28:17.447091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomPhoBERTForTokenClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForTokenClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Định nghĩa lại lớp mô hình\n",
    "class CustomPhoBERTForTokenClassification(RobertaForTokenClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        label_counts = Counter([label for sentence in balanced_train_data for label in sentence['ner_labels']])\n",
    "        total = sum(label_counts.values())\n",
    "        class_weights = torch.tensor([total / (len(label2id) * label_counts.get(label, 1)) * (20 if label in ['I-ĐT', 'B-ĐT'] else 10 if label != 'O' else 1) for label in label2id], dtype=torch.float)\n",
    "        self.register_buffer('class_weights', class_weights)\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "# Tải mô hình và tokenizer\n",
    "model_path = \"/kaggle/working/results/final_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = CustomPhoBERTForTokenClassification.from_pretrained(model_path, local_files_only=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T07:28:30.733523Z",
     "iopub.status.busy": "2025-04-08T07:28:30.733232Z",
     "iopub.status.idle": "2025-04-08T07:28:31.011006Z",
     "shell.execute_reply": "2025-04-08T07:28:31.010288Z",
     "shell.execute_reply.started": "2025-04-08T07:28:30.733501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    pred_labels = [[id2label[p] for p, l in zip(pred, label) if l != -100] for pred, label in zip(predictions, labels)]\n",
    "    results = metric.compute(predictions=pred_labels, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T07:28:36.445863Z",
     "iopub.status.busy": "2025-04-08T07:28:36.445513Z",
     "iopub.status.idle": "2025-04-08T07:29:35.548593Z",
     "shell.execute_reply": "2025-04-08T07:29:35.547650Z",
     "shell.execute_reply.started": "2025-04-08T07:28:36.445838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 7.501443386077881, 'eval_model_preparation_time': 0.0033, 'eval_precision': 9.227475731738825e-06, 'eval_recall': 3.803872342044201e-05, 'eval_f1': 1.485211011354438e-05, 'eval_accuracy': 0.0023320441720179022, 'eval_runtime': 58.8444, 'eval_samples_per_second': 174.664, 'eval_steps_per_second': 1.377}\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa lại TrainingArguments (chỉ cần để đánh giá, không huấn luyện)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_eval_batch_size=128,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Tạo Trainer để đánh giá\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Đánh giá trên tập test\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:29:10.415964Z",
     "iopub.status.busy": "2025-04-08T11:29:10.415642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Dự đoán trên tập test\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "pred_labels = [[id2label[p] for p, l in zip(pred, label) if l != -100] for pred, label in zip(predictions, labels)]\n",
    "results = metric.compute(predictions=pred_labels, references=true_labels, zero_division=0)\n",
    "print(\"\\nDetailed Test Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "true_counts = Counter([label for sentence in true_labels for label in sentence])\n",
    "pred_counts = Counter([label for sentence in pred_labels for label in sentence])\n",
    "print(\"\\nTrue label counts:\", true_counts)\n",
    "print(\"Predicted label counts:\", pred_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T08:04:23.557718Z",
     "iopub.status.busy": "2025-04-08T08:04:23.557351Z",
     "iopub.status.idle": "2025-04-08T08:05:26.220474Z",
     "shell.execute_reply": "2025-04-08T08:05:26.219608Z",
     "shell.execute_reply.started": "2025-04-08T08:04:23.557688Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [81/81 3:25:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev results: {'eval_loss': 0.2277332842350006, 'eval_model_preparation_time': 0.0033, 'eval_precision': 0.9350668800838692, 'eval_recall': 0.9619906974952572, 'eval_f1': 0.9483377318726384, 'eval_accuracy': 0.986095948568656, 'eval_runtime': 62.6519, 'eval_samples_per_second': 164.48, 'eval_steps_per_second': 1.293}\n"
     ]
    }
   ],
   "source": [
    "dev_results = trainer.evaluate(dev_dataset)\n",
    "print(\"Dev results:\", dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T08:08:01.240058Z",
     "iopub.status.busy": "2025-04-08T08:08:01.239667Z",
     "iopub.status.idle": "2025-04-08T08:08:01.351505Z",
     "shell.execute_reply": "2025-04-08T08:08:01.350526Z",
     "shell.execute_reply.started": "2025-04-08T08:08:01.240034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0203,  0.0399, -0.0246,  ..., -0.0367, -0.0092,  0.0497],\n",
      "        [ 0.0265, -0.0450,  0.0081,  ..., -0.0038, -0.0024, -0.0053],\n",
      "        [ 0.0243, -0.0044, -0.0061,  ...,  0.0212, -0.0468, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0554, -0.0478, -0.0294,  ...,  0.0069, -0.0335,  0.0336],\n",
      "        [-0.0003,  0.0242, -0.0268,  ...,  0.0210, -0.0036,  0.0217],\n",
      "        [ 0.0441,  0.0248, -0.0114,  ..., -0.0440, -0.0191,  0.0306]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.classifier.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:28:58.154459Z",
     "iopub.status.busy": "2025-04-08T11:28:58.154073Z",
     "iopub.status.idle": "2025-04-08T11:28:58.188524Z",
     "shell.execute_reply": "2025-04-08T11:28:58.187492Z",
     "shell.execute_reply.started": "2025-04-08T11:28:58.154430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens (first sentence): ['Cấp', 'lại', 'Giấy', 'chứng nhận', 'huấn luyện', 'kỹ thuật', 'an toàn', 'vật liệu', 'nổ', 'công nghiệp', 'thuộc', 'thẩm quyền', 'giải quyết', 'của', 'sở công thương', 'thực hiện', 'Trực tiếp', '3', 'Ngày', 'Dịch vụ', 'bưu chính', '3', 'Ngày']\n",
      "Sample labels (first sentence): ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CQ', 'O', 'O', 'B-NG', 'I-NG', 'O', 'O', 'B-NG', 'I-NG']\n",
      "Sample input_tokens (first sentence): ['<s>', 'Cấp', 'lại', 'Giấy', 'chứng', 'nhận', 'huấn', 'luyện', 'kỹ', 'thuật', 'an', 'toàn', 'vật', 'liệu', 'nổ', 'công', 'nghiệp', 'thuộc', 'thẩm', 'quyền', 'giải', 'quyết', 'của', 'sở', 'công', 'thương', 'thực', 'hiện', 'Trực', 'tiếp', '3', 'Ngày', 'Dịch', 'vụ', 'b@@', 'ưu', 'chính', '3', 'Ngày', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Sample word_ids (first sentence): [None, 0, 1, 2, 3, None, 4, None, 5, None, 6, None, 7, None, 8, 9, None, 10, 11, None, 12, None, 13, 14, None, None, 15, None, 16, None, 17, 18, 19, None, 20, None, None, 21, 22, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Sample label_ids (first sentence): [-100, 4, 4, 4, 4, -100, 4, -100, 4, -100, 4, -100, 4, -100, 4, 4, -100, 4, 4, -100, 4, -100, 4, 7, -100, -100, 4, -100, 4, -100, 1, 5, 4, -100, 4, -100, -100, 1, 5, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "input_ids shape: torch.Size([1, 128])\n",
      "attention_mask shape: torch.Size([1, 128])\n",
      "logits shape: torch.Size([128, 11])\n",
      "Adjusted logits shape: torch.Size([1, 128, 11])\n",
      "predictions shape: torch.Size([1, 128])\n",
      "True labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CQ', 'O', 'O', 'B-NG', 'I-NG', 'O', 'O', 'B-NG', 'I-NG']\n",
      "Predicted labels: ['I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG', 'I-NG']\n"
     ]
    }
   ],
   "source": [
    "# Lấy mẫu từ tập test\n",
    "sample_sentence = test_data[0]\n",
    "\n",
    "# Đảm bảo input_ids và attention_mask có batch dimension\n",
    "input_ids, attention_mask, _ = convert_to_features([sample_sentence], max_len=128)\n",
    "print(\"input_ids shape:\", input_ids.shape)  # Phải là [1, 128]\n",
    "print(\"attention_mask shape:\", attention_mask.shape)  # Phải là [1, 128]\n",
    "\n",
    "# Đưa dữ liệu lên GPU\n",
    "input_ids = input_ids.to('cuda')\n",
    "attention_mask = attention_mask.to('cuda')\n",
    "\n",
    "# Dự đoán\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask=attention_mask)[0]\n",
    "    print(\"logits shape:\", logits.shape)  # Phải là [1, 128, 11]\n",
    "    if len(logits.shape) == 2:  # Nếu logits có shape [128, 11]\n",
    "        logits = logits.unsqueeze(0)  # Thêm batch dimension: [1, 128, 11]\n",
    "        print(\"Adjusted logits shape:\", logits.shape)\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    print(\"predictions shape:\", predictions.shape)  # Phải là [1, 128]\n",
    "\n",
    "# Chuyển đổi dự đoán thành nhãn\n",
    "pred_labels = [id2label[p.item()] for p in predictions[0] if p != -100]\n",
    "print(\"True labels:\", sample_sentence['ner_labels'])\n",
    "print(\"Predicted labels:\", pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6751927,
     "sourceId": 10868382,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
